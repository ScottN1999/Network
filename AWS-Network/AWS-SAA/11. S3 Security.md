# S3 Security


## S3 Object Encryption

Can be done in 4 methods:

- **Server-side encryption (SSE)**
  - Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3) - **Enabled by default**
    - Encrypts S3 Objects using keys handled, managed, and owned by AWS
  - Server-Side Encryption with KMS Keys stored in AWS KMS (SSE-KMS)
    - Leverages AWS Key Managment Service (AWS KMS) to manage encryption keys
  - Server-Side Encryption with Customer-Provided Keys (SEE-C)
    - When you want to managed your own encryption keys

- **Client-Side Encryption**
Encrypting the data client side before it hits the bucket

## SSE-S3

Encryption using keys handled, managed, and owned by AWS - encryption type is AES-256 therefore must set header "x-amz-server-side-encryption": "AES256"

SSE-S3 is enabled by default for new buckets and objects

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/111e77e7-d5e6-48fd-b93a-cc612e57a12a)

* I got this wrong initially > picked A, pretty stupid as that's for in transit

## SSE-KMS

Encryption using keys handled and managed by AWS KMS, KMS advantages: User control + audit key usage using CloudTrail

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/6b9fdf1a-ac78-409f-b5e5-7285096a46ec)


- Object is encrypted server-side. Must set header "x-amz-server-side-encryption": "aws:kms"

**Limitiations** 
If you use SSE-KMS, you may be impacted by KMS limits, when you upload, it calls the **GenerateDataKey** KMS API and when you download it called the **Decrypt** KMS API.

These count towards the KMS quota per second (5500, 10000, 30000 req/s based on region).

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/71e43220-d868-4655-a459-0dc426805fdd)

## SSE - C
Server-Side encryption using keys fully managed by the customer outside of AWS - Amazon S3 does NOT store the encryption key you provide.

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/bd6b96b3-dbbd-4c38-97ef-3ea0677123ba)


- HTTPS must be used - Encryption key must provided in HTTP headers, for every HTTP request made

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/094bfe55-ad12-4a1f-b6bd-981906083367)


## Client-Side Encryption
Use client libraries such as **Amazon S3 Client-Side Encryption Library** - client must encrpt data themselves before sending to S3 and clients must decrypt data themselves when retrieving from S3 (customer fully manages the keys and encryption cycle)

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/65c06c62-7e60-448c-831b-0dd5f882f3ba)


![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/b4dfbb2a-d078-4013-9898-0f0f582c2fbb)

## Encryption in Transit (SSL/TLS)

S3 exposes two endpointsL
  - HTTP unencrypted, HTTPS encrypted duh

HTTPS is recommended and mandatory for SSE-C

This can be forced by a bucket policy through aws:SecureTransport:

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/6bf991dc-1c96-4e1a-a1d3-8f6a76321da9)

## Default Encryption vs Bucket Policies

- SSE-S3 is automatically applied to new objects stored in S3 Bucket, optionally - you can "force encryption" using a bucket policy and refuse any API call to PUT an S3 without encryption headers (SSE-KMS or SSE-C)

**Note: Bucket Policies are evaluate before "Default Encryption"**

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/cbe6747f-a845-497b-bc32-7caa01bfa9a3)


## AWS Cross-origin Resource Sharing (CORS)

Origin = scheme (protocol) + host (domain) + port
  - Example: https://www.example.com (implied port is 443 for https)

CORS is a **web browser** based mechanism to allow or deny requests to other origins while visiting the main origin

Same origins look like: **http://example.com**/app1 and **http://example.com**/app2 (same host and protocol http | port 80)

different origins could look like: **http://example.com** and _http://other.example.com_

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/253003af-867a-4c6c-b208-09268e138cc1)


The requests won't be fulfilled unless the other origin allows for the requests, using CORS Headers (e.g. Access-Control-Allow-Origin)

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/3a5332f9-abae-442b-a509-3583b403d316)

## WTF does this gotta do with S3

If a client makes a cross-region request on our S3 Bucket, we need to enable the correct CORS headers - you can allow for a specific origin or for * (all origins).

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/1a7018aa-e6f2-4926-a346-78601bcb9f51)

## S3 MFA Delete

Can allow MFA to be a requirement for:
- Permanently delete a object version
- SuspendVersioning on the bucket

MFA won't be required to:
- Enable versioning
- List deleted versions

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/04f590d4-d1d7-4fe4-a2d8-ad2d55ea3b02)


To use MFA Delete, **Versioning must be enabled on the bucket** 

**Only the bucket owner (root account) can enable/disable MFA delete** interesting an IAM user cannot do this

## S3 Access Logs
For audit purposes, may be a good idea - any request made to S3, from any account, unauthorised or denied, will be logged into another s3 bucket - that can be alaysed using data analysis tools (e.g. Athena).

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/ae1d5a58-1f15-4cd2-bb1c-dd51e4b8ef79)


**The target locking bucket must be in the same AWS region**

Do not set your logging bucket to be the monitored bucket, this will create a logging loop and your bucket will grow exponentially. _this will make bezos very happy if you do so_

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/e8b36ed5-38e7-45ea-8d42-4b90a970ae26)

 
## S3 - Pre-Signed URLS

too boring

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/76050b7d-b545-4ee1-ae72-1aaa000f5e3c)


## Glacier Vault Lock
Adopt a WORM model (write once ready many)

Firstly, we need to create a Vault Lock Policy on the glacier - will lock the policy for future edits (can no longer be changed or deleted) (helpful for compliance and data retention).

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/7279fdf8-82b0-408e-9974-bc549adf463d)


### S3 Object Lock (versioning must be enabled)
Adopt a WORM model (write once ready many)

Block an object version deletion for a specified amount of a time.

2 retention modes:
- Compliance (similiar to glacier vaut lock)
  - Object versions can't be overwritten or deleted by any user, including the root user
  - Objects retention modes can't be changed, and retention periods can't be shortened

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/bc2abf27-fcb8-4772-a38e-dfabc83fb2cc)


- Governance (more leniant)
  - Most user can't overrite or delete an object version or alter it's lock settings
  - Some users have special perms to change the retention or delete the object (given through IAM)
 
**Retention period:** Protect the object for a fixed period of time (can be extended)
**Legal hold:** Protect the object indefinitely, independent from retention period - can be freely placed and removed use the s3:PutObjectLegalHold IAM perm

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/e50014bf-7ab5-41d8-afcb-ffba9e8f3653)

* Stupid question that tricks you by not reading 1 word 'indefinitely', I did Governance which was technically correct if I didn't read indefinitely

## S3 Access Points

Simplifies the security management for S3 Buckets (rather than continously updating bucket policies).

Each Access Point has:
  - It's own DNS name (Internet Origin or VPC Origin)
  - Access Point Policy (similiar to bucket policy) - manage sec at scale

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/33a2ef84-1fad-4657-afa5-f87252cabba4)

**VPC Origin**

We can define the access point to be accessible only from within the VPC - you must create a **VPC Endpoint** to access the Access Point (Gateway or Interface Endpoint). The VPC Endpoint policy must allow access to the rarget bucket and Access Point

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/ae0930ea-4dcc-4ec0-8223-fb82ca80c9ea)

## S3 Object Lambda
Use Lambda Functions to change the object before it is retrieved by the caller application. Only one S3 bucket is needed, on top of which we create **S3 Access Point** and **S3 Object Lambda Access Points**

This can be helpful in the below scenario, instead of creating a whole new redacted object bucket we can use Access Points with a lambda function to redact the object > then the applications will access the data through the S3 Object Lambda Access Point which will invoke the function

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/eeb1c772-fd27-4981-aedf-76eb3bedb769)

![image](https://github.com/UpheldSmile/Virtual-Network/assets/49825639/f631cc13-9c83-4005-9acf-4b9922f8e6c7)

